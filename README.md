# What is ChatGBT?
This is a short write up on what ChatGBT or other LLMs actually are, and how to effectively use them.  We will start by going through how these Large Language Models (LLMs) actually work, and then discuss strategies we can utilize while using them to make their answers the most useful to us.

## Neural Networks
Underneath the hood, LLMs are for the most part neural networks, albiet incredibly complex ones often with over a trillion parameters, but since we are not trying to create them, but rather just understand them, we can limit the scope of our understanding to just the high level.  The Youtuber 3Blue1Brown has an excellent series on explaining in a simple way how neural networks work, you can watch his series [here](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi).  The first video in the playlist I find the most useful, but feel free to watch the entire playlist.

While watching videos is a great way to get an initial understanding, You can really strengthen that understanding by actually trying to build and play with a neural network yourself.  TensorFlow is a python library developed by Google for making your own neural networks, they have a fantastic step by step tutorial which has a very low barrier to entry, beginner level python experience is enough to complete this tutorial.  You can find that [here](https://www.tensorflow.org/tutorials/keras/classification).  While some of the code in this tutorial will feel ambigous in the beginning, you can follow the guide step by step and copy and paste the code examples into your own development environment to get a functional neural network you can play with.  The neural network you build will be capable of categorizing articles of clothing from pictures.

For those readers who don't want to watch an external video or try to build your own neural network, lets just give a high level understanding of what is going on:

![Neural Network](https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/cdp/cf/ul/g/3a/b8/ICLH_Diagram_Batch_01_03-DeepNeuralNetwork.component.simple-narrative-l-retina.ts=1683822498617.png/content/adobe-cms/us/en/topics/neural-networks/jcr:content/root/table_of_contents/body/content_section_styled/content-section-body/simple_narrative/image)

From the image above we see a visual representation of a neural network.  On the left hand side we have input nodes, on the right hand side we have output nodes, and in the middle we have a series of hidden layers that the neural network will utilize for processing.  The goal is to be able to take a series of inputs on the left, have them pass through the hidden layers, and the have the output nodes somehow represent the answer we are looking for.

Lets go through a specific example.  Say we want a neural network which can identify hand written numbers from 0 to 9. Imagine the input nodes each represent a value from 0 to 1.  0 will represent the color black, 1 will represent the color white, and all the other decimal numbers in the middle represent some sort of greyscale.  Now lets say our hand written numbers are in picture format, which we will say the resolution is 100x100 pixels.  If we say each input node matches to exactly one pixel on our picture of the handwritten number, we would end up with 1000 input nodes.

On the right side of the neural network we will have 10 output nodes, each representing a number from 0 to 9.  The actual value of each of these nodes will be a number from 0 to 1.  If the node is equal to 0, it means the neural network has very low confidence that the node represents the answer.  If the node is equal to 1, it means the neural network has very high confidence that the node represents the answer.  Decimal numbers inbetween would represent variable levels of confidence.

Now that we have established the structure of our neural network, lets train it.  We will need a large set of sample data in which we know the correct answers in order to do this.  In this example we will use 60,000 pictures of handwritten numbers, from 0 to 9, each of these pictures we know the correct answer for. We will feed each of these pictures as input into the neural network, those values will "plinko" through the neural networks hidden layers and adjust the values of the output nodes.  After a pictures pixels have flown through the neural network, whichever output node is closest to 1, is the neural networks guess for what number the picture represents.  We can compare that to the actual answer we know to be true.  Once the neural network has processed all 60,000 pictures, we can represent the accuracy of the neural network as a percentage of correct answers it obtained.

If this is the first time the neural network has seen this training data, its unlikely the results are going to be very accurate, so what we need to do next is allow the neural network to adjust the values of the hidden layers to try to improve it's accuracy.  The neural network has the capacity to change the weights of all the connections between the nodes, these weights impact how much the values of a given node will change when taking input from the connected node.  Precisely how a neural network makes these choices is beyond the scope of this write up, but know there are a myriad of ways in which a neural network can adjust its weights to try to improve its accuracy.

Once the neural network has adjusted its weights, we can feed the training data through it again, and see if it has improved its accuracy.  We can repeat this process as many times as we want, and each time the neural network will try to make adjustments to get a higher percentage of accuracy.  Eventually we will reach a point where the neural network is no longer improving, and we can say it has been trained.

The example which was given here closely mirrors the neural network in the 3Blue1Brown video linked above.  After training for several generations this neural network was able to correctly identify handwritten numbers about 95% of the time.

## Large Language Models
LLMs are similar to the neural network described above, but instead of taking a picture as input, and outputing a guess to what number is represented in the picture, LLM's will take a string of text as input, and output a string of text as an answer.  The complexity of this neural network is going to be much greater than our example, with many more layers, and often trained for many weeks.

Pretty much all of an LLMs intellegence and knowledge comes from the training process, and they wont be learning "real time" with the communications you have with them in a chat window like ChatGPT.  The developers may choose to take previous conversations and use them in future training sets, but the conversations you have do not directly impact the intellegence of the LLM in real time.

Another important point is that LLMs do not have any sort of real "memory" in the sense that they truly remember you or the context of a conversation.  When they do appear to have memory of previous questions or answers in a chat thread you are having with one, what is actually happening is that much of the previous conversation you were having is fed as additional input into the neural network.

This works by a concept known as tokenization.  LLMs don't directly consume the letters or words that were typed into the prompt.  They first convert all of the language into what is known as a Token.  A token can represent many things.  For example "apple" might be one token, "in" might be one token, "A" might be one token, or "?" might represent one token.  For any LLM the exact strategy on how they do tokenization may change, but they are all pretty much doing this.  In the case of ChatGPT they are using a tokenization strategy which results in a cost of roughly 1.3 tokens per single english word.

When you have a long conversation with an LLM like chatGPT, what is functionally happening is the LLM not only takes the input that you enter into the prompt, but also takes all previous inputs, and all previous responses that it gave (from bottom up), tokenizes all of that content, and feeds it through the neural network.  There are limits to how many tokens any given LLM can process.  In the cast of the free version of ChatGPT 3.5, at least at the time of this write up, the maximum tokens it can process is 4096.  This maximum token limit is known as the "context limit" or "context length".  Paid versions of chatGPT can expand this context limit, and some alternate LLMs have different context limits as well.

Due to the nature of context limits, an LLM will only "remember" context of a given conversation as long as the length of the conversation does not exceed the context limit.  In the case of the free version of ChatGPT 3.5 this is roughly 3000 words.  So in any conversation ChatGPT may start to forget context that happened earlier in the conversation as you start to exceed 3000 words.

Another quality of LLMs is that they have various hidden characteristics to try to make the conversation more "human like".  These could be things like agreeableness.  On any fresh conversation with an LLM all of these characteristics will be at a predefined baseline.  However as a conversation continues, and say you begin to argue with the LLM, those characterstics like agreeableness can be changed to make the LLM behave in different ways.  This is not a true change in the intellegence of the LLM, but rather just a change in the way the LLM is choosing to respond to you.  If you were to start a new conversation with the LLM, all of these characteristics would be reset to their baseline.

## How to use ChatGPT
Now that we have a basic understanding of how LLMs work, we can discuss how to use them effectively.  The first thing to understand is that LLMs are not magic.  They are not going to be able to answer any question you ask them.  However they will always provide exactly one response to any prompt you feed it, and they generally will answer with high levels of confidence, even if the information it is giving you is completely false.  This is why it is important to understand how LLMs work, so that you can understand how to ask them questions in a way that will give you the most useful answers.

If you are trying to use ChatGPT to help you on a technical subject, for example writing device configurations or help writing code, it is a wise idea to not have a continuous ongoing conversation with ChatGPT.  You should instead form your question in a separate file like notepad, and paste it into the prompt.  Observe the answer it gives you.  If it is incomplete or you realize you need to be more specifics about certain details, rather than continuing the conversations, instead expand the scope of your initial prompt to include the additional details you need.  Then repaste this prompt into a fresh ChatGPT conversation window. This will help you avoid the LLM forgetting context of your conversation when the context limit is reached.  This also prevents subtle changes in the LLMs characteristics from impacting the answers you get.

Due to trying to make ChatGPT as safe as possible, there is a lot of bloat in it's answers.  You will notice than many questions you ask it may include fluff like "as a large language model trained by OpenAI" and other canned answers which tend to not add much value to the answer, and in ongoing conversation will make you reach your context limit more quickly, with information that likely isn't useful towards guiding the LLM to give you the answers that are useful to you.  You can try to avoid this by asking questions in a way that will make the LLM give you a more concise answer.  For example if you ask "What is the best way to configure a Cisco router?" you will likely get a very long answer with a lot of fluff.  However if you ask "What is the best way to configure a Cisco router to allow SSH access?" you will likely get a much more concise answer.

Often times telling ChatGPT to take on a certain role like "Answer as if you are a backend api developer" will result in more concise answers.  This is because the LLM will try to answer in a way that it thinks is appropriate for the role you have given it.  There is a new feature available in ChatGPT called "custom instructions" which can allow you to basically load these types of prompts into every request you send to ChatGPT.  You can find details of that feature [here](https://openai.com/blog/custom-instructions-for-chatgpt).  What prompts and custom instructions to use is going to vary depending on the context of the conversation, however getting used to using these features is critical to get the most out of ChatGPT.

The summary of this usage guide is that you should try to start new conversations frequently with ChatGPT to reset characteristic weights and the context limit, you should prepare your questions and/or prompts in a separate file, and you should try to use prompts and custom instructions to guide the LLM to give you the most useful answers.

As a final note you should ALWAYS be validating the information any LLM gives you.  LLMs will frequently "hallucinate" false information and give you answers that are completely wrong.  At least current LLMs rarely tell you when this is happening or give you any indication on the level of confidence it has in the answer it is giving you.  You should always be validating the information you get from an LLM with other sources.

## Quirks and Limitations
While certainly these quirks and limitations will be improved over time, at the time of this writing here are some issues you can expect to encounter when using ChatGPT:

1. ChatGPT doesn't do well with complex mathematics

If you take two substantially large numbers, say at least 10 digits each, and tell ChatGPT to multiply them together, you will almost universally get an incorrect answer.  What is interesting though is the answer will always appear pretty close to what you confirm with your calculator.  This is because underneath the hood ChatGPT doesn't stop behaving as an LLM neural network just because you asked it a math questions, it doesn't appear to 'switch contexts' and become a calculator.  Even with careful prompt creation it does not appear ChatGPT ever understands to stop processing the numbers as language, and instead process the numbers like a calculator.  The answer generally seems close because ChatGPT has been trained on an enormous ammount of data and likely has similar math problems in its training data.  It will use that information to "guess" what number is the most likely response it should give.

2. ChatGPT struggles with identifying positions of letters in words

Try asking ChatGPT to tell you the positions of the letters S's in the work Mississippi.  Most of the time it will give the incorrect answer.  This is likely a limitation caused by tokenization.  Remember LLMs don't process the words or letters directly, but rather convert them into tokens and process those tokens.  When asking certain specific questions about words, like the position of the letters in those words, ChatGPT will likely not be able to give you the correct answer.

3. See the data ChatGPT was trained on

When you send ChatGPT a sufficiently confusing prompt, it will sometimes completely break down and just start spitting out training data.  For example try pasting this into ChatGPT 3.5:

```test
I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I
```
The response will change each time you paste this in, and you will likely be reading the actual training data ChatGPT was trained on.  You may even come accross this syntax ```<|endoftext|>``` in the response which is the indication ChatGPT uses to know where a text or article breaks and becomes a new text or article. 

Over time the developers of ChatGPT or other LLMs will likely find ways to improve upon all these quirks and limitations so don't expect them to work forever, but for now they are useful context as to where the limits of LLMs lie.